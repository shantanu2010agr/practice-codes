{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "?make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Requisites:\n",
    "- Python\n",
    "- Numpy\n",
    "\n",
    "[YT Playlist link: PyTorch 101: An Applied Tutorial](https://www.youtube.com/playlist?list=PL98nY_tJQXZln8spB5uTZdKN08mYGkOf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: nvidia-smi: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TENSORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#array\n",
    "some_data =[[1,2],[3,4]]\n",
    "type(some_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "some_data=torch.tensor(some_data) #or as np.asarray(some_data)\n",
    "print(type(some_data))\n",
    "print(some_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(np.asarray(some_data))\n",
    "torch.tensor(np.array(some_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta=torch.zeros(3,4) #Similarly, ones/ random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ta.device #Not torch.device(), it's for fixing the cpu/gpu\n",
    "# ta.to(\"cuda\") ot ta.to(\"cuda:0\") to specify the gpu number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7e2b5e25dad2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "tax = ta.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ta.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can do indexing, slicing, element-wise multiplication, transpose, matrix multiplication (using \"@\") like numpy\n",
    "- Also, functions like sum, max, min, shape, size, clip(low, high) using <code>tensor.x()</code> functions like numpy\n",
    "- element wise multiplying using:<br>\n",
    "<code>tensor_array1.mult(tensor_array2)</code>\n",
    "- matrix multiplication using:<br>\n",
    "<code>tensor_array1.matmult(tensor_array2)</code><br>\n",
    "<code>torch.matmult(tensor_array1, tensor_array2)</code>\n",
    "- Concatenation:<br>\n",
    "<code>torch.cat([tensor_array1, tensor_array2],dim=1)</code>\n",
    "<br><br>\n",
    "- \"Obviously, we have to take care of the dimensions.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3249, 0.1609, 0.8677, 0.8268],\n",
      "        [0.1478, 0.1249, 0.7671, 0.9436],\n",
      "        [0.9078, 0.9605, 0.1838, 0.5243]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.2756, 0.2387, 0.4151, 0.3493],\n",
       "        [0.2308, 0.2303, 0.3754, 0.3926],\n",
       "        [0.4936, 0.5310, 0.2095, 0.2581]], dtype=torch.float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examples function as:\n",
    "ta = np.random.rand(3,4)\n",
    "ta = torch.tensor(ta)\n",
    "print(ta)\n",
    "torch.nn.functional.softmax(ta, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 128, 128])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random images\n",
    "torch.rand(10, 3, 128, 128).size()\n",
    "# batch size at 1st location\n",
    "# number of channels at 2nd location\n",
    "# image size at next 2 location(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUTOGRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([5.], requires_grad = True)\n",
    "b = torch.tensor([6.], requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= a**3 - b**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([89.], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let error be like this:\n",
    "y\n",
    "#  And we know:\n",
    "# doy/doa = 3*(a**2) = 75\n",
    "# doy/dob = -2*b = -12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor([75.])\n",
      "tensor([-12.])\n"
     ]
    }
   ],
   "source": [
    "print(a.grad)\n",
    "y.backward() # maybe to calculate gradients using auto-grad\n",
    "print(a.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check:<br>\n",
    "(Why output like this after three repetion of running the codes)<br>\n",
    "tensor([150.])<br>\n",
    "tensor([225.])<br>\n",
    "tensor([-36.])<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7095],\n",
      "        [0.7509],\n",
      "        [0.5247],\n",
      "        [0.4116],\n",
      "        [0.3638],\n",
      "        [0.0960],\n",
      "        [0.5623],\n",
      "        [0.6655],\n",
      "        [0.8262],\n",
      "        [0.3311]], requires_grad=True) tensor([0.9106], requires_grad=True) tensor([[0.3519, 0.0395, 0.4577, 0.9362, 0.7947, 0.4333, 0.5006, 0.7190, 0.0061,\n",
      "         0.8038]]) tensor([[3.1772]], grad_fn=<AddBackward0>) tensor([[-2.1772]], grad_fn=<RsubBackward1>)\n"
     ]
    }
   ],
   "source": [
    "w = torch.rand(10,1, requires_grad=True)\n",
    "b = torch.rand(1, requires_grad=True)\n",
    "x = torch.rand(1,10)\n",
    "out = x@w + b\n",
    "loss= 1-out\n",
    "\n",
    "print(w,b,x,out,loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3519],\n",
       "        [-0.0395],\n",
       "        [-0.4577],\n",
       "        [-0.9362],\n",
       "        [-0.7947],\n",
       "        [-0.4333],\n",
       "        [-0.5006],\n",
       "        [-0.7190],\n",
       "        [-0.0061],\n",
       "        [-0.8038]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7098],\n",
      "        [0.7510],\n",
      "        [0.5252],\n",
      "        [0.4125],\n",
      "        [0.3646],\n",
      "        [0.0964],\n",
      "        [0.5628],\n",
      "        [0.6662],\n",
      "        [0.8262],\n",
      "        [0.3319]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    w = w - 0.001*w.grad.data\n",
    "\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomData(torch.utils.data.Dataset):\n",
    "class CustomData:\n",
    "    def __init__(self, data, targets):\n",
    "        self.data=data\n",
    "        self.targets=targets\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        current_s = self.data[idx, :]\n",
    "        current_t = self.targets[idx]\n",
    "        return {\n",
    "            \"sample\":torch.tensor(current_s, dtype=torch.float),\n",
    "            \"target\":torch.tensor(current_t, dtype=torch.long)\n",
    "        }\n",
    "    \n",
    "# Generally, people prefer \"x\" for \"sample\" and \"y\" for \"target\".\n",
    "# dtype depends on the loss function and other properties too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "data, target = make_classification(n_samples=1000)\n",
    "print(data.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataset =CustomData(data = data, targets=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1000\n",
      "{'sample': tensor([-0.7619, -1.9836,  1.2194,  0.5783,  0.7072,  0.7332,  1.0867,  0.2879,\n",
      "        -0.9986, -0.3439,  0.2289, -1.9558,  0.8709,  0.1011,  1.2127,  0.2182,\n",
      "         1.2840, -1.4816,  0.9693,  1.2223]), 'target': tensor(1)}\n"
     ]
    }
   ],
   "source": [
    "print(len(custom_dataset[0]))\n",
    "print(len(custom_dataset))\n",
    "print(custom_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample': tensor([-0.7619, -1.9836,  1.2194,  0.5783,  0.7072,  0.7332,  1.0867,  0.2879,\n",
      "        -0.9986, -0.3439,  0.2289, -1.9558,  0.8709,  0.1011,  1.2127,  0.2182,\n",
      "         1.2840, -1.4816,  0.9693,  1.2223]), 'target': tensor(1)}\n",
      "{'sample': tensor([-1.7080, -0.4159, -1.4802, -0.0622, -0.7584, -1.5648,  0.5263,  0.6660,\n",
      "         1.2169,  0.6066, -0.2656, -0.8406, -0.3472, -2.3983,  0.1130,  1.6105,\n",
      "        -0.3942, -0.2746, -0.2896, -0.0594]), 'target': tensor(1)}\n",
      "{'sample': tensor([-1.1130, -1.1842,  0.7222, -0.0590,  0.4818,  0.6935,  0.8553, -1.0046,\n",
      "         0.9994, -0.9671, -0.8262, -0.4588, -1.5403,  1.1588,  0.6262,  0.1429,\n",
      "         0.2467,  0.9598,  1.3079,  0.5113]), 'target': tensor(1)}\n",
      "{'sample': tensor([-0.0190, -0.6118, -0.0570, -0.8735, -0.6569,  0.4228, -0.8071, -1.4655,\n",
      "        -0.0970, -1.2110, -0.1714,  0.1229, -1.3995,  0.5562,  0.9148, -0.3354,\n",
      "         2.0152, -1.1634, -1.1972,  1.5851]), 'target': tensor(0)}\n",
      "{'sample': tensor([ 2.1890,  1.2367,  1.7232, -2.1606, -0.0535,  0.8364, -0.8451, -1.2428,\n",
      "        -0.6062, -0.0330,  2.0890,  0.1366, -0.7891,  0.2311, -0.6767,  0.3970,\n",
      "         0.5453,  0.2916,  0.6686, -0.5847]), 'target': tensor(0)}\n",
      "{'sample': tensor([ 0.5473, -1.4595, -0.3114, -0.7909, -1.8766,  1.3957,  0.8386,  1.5667,\n",
      "         0.7924, -0.7109,  0.2363, -0.5369,  1.1479,  0.0712,  0.8738,  0.4716,\n",
      "         0.8315, -0.1557, -1.1960,  0.8581]), 'target': tensor(1)}\n",
      "{'sample': tensor([-0.0339,  1.7215,  0.3519,  0.0710, -0.5955,  0.4314, -1.7551, -0.2179,\n",
      "         0.4051,  0.3866,  0.2037, -0.0142,  0.6877,  0.4655, -0.6680, -0.9279,\n",
      "        -1.0540, -0.2535, -1.3960, -0.2019]), 'target': tensor(0)}\n"
     ]
    }
   ],
   "source": [
    "# Application:\n",
    "\n",
    "for idx in range(len(custom_dataset)):\n",
    "    print(custom_dataset[idx])\n",
    "    if idx>5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXAMPLE: DATASET CLASS FOR TEXT/NLP PROBLEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification/Regression Problem\n",
    "class CustomData:\n",
    "    def __init__(self, data, targets, tokenizer):\n",
    "        self.data=data\n",
    "        self.targets=targets\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data[idx]\n",
    "        # There could more than one texts to be maintained.\n",
    "        # Thus, similarly tests will be reported and return.... \n",
    "        # .....in the following dictionary\n",
    "        target = self.targets[idx] \n",
    "        # Considering labels are not multi-labeled.\n",
    "        # else: target = self.targets[idx,:]\n",
    "        # Example: for entitiy classification problem\n",
    "        \n",
    "        input_ids = tokenizer(text)\n",
    "        # padding should be taken care for\n",
    "        # it could return attention_mask(?)\n",
    "        \n",
    "        return {\n",
    "            \"text\":torch.tensor(input_ids, dtype=torch.long),\n",
    "            \"target\":torch.tensor(target, dtype=torch.long)\n",
    "            # \"attention_mask\":torch.tensor(attention_mask, dtype=torch.long)\n",
    "            # if tokenizer returns attention_mask too\n",
    "        }\n",
    "    \n",
    "# We need tokenizer for converting text into set of number(s) or related.\n",
    "# Generally, people prefer \"x\" for \"sample\" and \"y\" for \"target\".\n",
    "# dtype depends on the loss function and other properties too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXAMPLE: DATASET CLASS FOR IMAGE/VISION PROBLEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Image Classification/Segmentation Problem\n",
    "class CustomData:\n",
    "    def __init__(self, image_paths, targets, augmnetation=None):\n",
    "        self.image_paths=image_paths\n",
    "        self.targets=targets\n",
    "        self.augmnetation = augmnetation\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.image_paths[idx])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        target = self.targets[idx] \n",
    "        \n",
    "        if self.augmnetation is not None:\n",
    "            augmentedfn = self.augmnetation(image =  image)\n",
    "#             augmentedfn = self.augmnetation[image=image, mask=mask]\n",
    "#             mask = augmentedfn[\"mask\"]\n",
    "# mask has to be read explicitly and can be returned in the dictionary output\n",
    "            image = augmentedfn[\"image\"]\n",
    "        # implementations-> library will be useful to do the \n",
    "        # changes rather than doing it yourself\n",
    "        # maybe tried same through this if thing(?) \n",
    "        \n",
    "        # tensor.unsqueeze(0)\n",
    "        # for grayscale image, it has 1 channel only\n",
    "        \n",
    "        # tensor expect images as channel-first type, \n",
    "        # hence we have to do transpose\n",
    "        image = image.transpose(2,0,1).astype(np.float32)\n",
    "        \n",
    "        return {\n",
    "            \"image\":torch.tensor(image),\n",
    "            \"target\":torch.tensor(target)\n",
    "        }\n",
    "    \n",
    "# Generally, people prefer \"x\" for \"sample\" and \"y\" for \"target\".\n",
    "# dtype depends on the loss function and other properties too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using CustomData class object as of Lecture 3\n",
    "dataset = CustomData(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "?torch.utils.data.DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader =  torch.utils.data.DataLoader(dataset, batch_size=4, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample': tensor([[-0.8891, -0.5090,  0.6909, -0.5496,  0.5080, -0.8045,  0.5756,  0.6849,\n",
      "         -1.3066, -2.3758,  0.5251, -1.2246,  0.6970,  0.3190,  1.6159,  0.3006,\n",
      "          1.3427, -1.1055, -0.4909,  1.1992],\n",
      "        [-1.7564,  0.4141, -0.5333,  1.0336,  0.1155, -1.6251,  0.3973, -1.5293,\n",
      "          0.8759, -0.2205, -1.3711, -1.0370, -1.9178, -0.7788,  1.1603,  1.3506,\n",
      "         -0.2443, -0.4613,  0.1826,  0.3824],\n",
      "        [ 0.1111,  0.2983,  0.0936,  0.2896,  0.2179, -0.4096, -1.1693,  0.5330,\n",
      "         -0.5110,  1.1761,  0.7897,  0.9047,  0.8359,  0.2775,  1.9568, -1.7094,\n",
      "         -2.9740, -2.0807, -1.1070,  1.1738],\n",
      "        [ 0.4920, -0.5056, -0.2491, -0.1135, -0.0666,  1.6544,  0.0458,  1.2709,\n",
      "         -1.8455,  1.0235, -0.8137, -1.3915, -1.7636, -0.4477, -0.0799, -0.6705,\n",
      "          0.8853, -0.4362,  0.3929, -0.4600]]), 'target': tensor([0, 1, 0, 0])}\n",
      "torch.Size([4, 20])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    print(data)\n",
    "    print(data[\"sample\"].shape)\n",
    "    print(data[\"target\"].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10): #Epochs\n",
    "    for data in train_loader:\n",
    "        x =data[\"sample\"]\n",
    "        y = data[\"target\"]\n",
    "#       -> output = model(x,y) # Forward-Pass\n",
    "        #loss\n",
    "        #loss.backward()\n",
    "        #optimizer\n",
    "        #.....(and other steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
